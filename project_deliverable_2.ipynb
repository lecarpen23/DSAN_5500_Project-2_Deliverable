{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running main to show framework and stubs...\n",
      "\n",
      "\n",
      "---Creating dataset---\n",
      "Error reading my_data.csv: [Errno 2] No such file or directory: 'my_data.csv'\n",
      "Loading my_data.csv...\n",
      "Error reading my_data.csv: [Errno 2] No such file or directory: 'my_data.csv'\n",
      "Cleaning...\n",
      "Exploring...\n",
      "\n",
      "\n",
      "---Creating TimeSeriesDataSet--- \n",
      "Error reading my_data.csv: [Errno 2] No such file or directory: 'my_data.csv'\n",
      "Loading my_data.csv...\n",
      "Error reading my_data.csv: [Errno 2] No such file or directory: 'my_data.csv'\n",
      "Cleaning Time Series Data Set...\n",
      "Exploring Time Series Data Set...\n",
      "\n",
      "\n",
      "---Creating QuantDataSet---\n",
      "Error reading my_data.csv: [Errno 2] No such file or directory: 'my_data.csv'\n",
      "Loading my_data.csv...\n",
      "Error reading my_data.csv: [Errno 2] No such file or directory: 'my_data.csv'\n",
      "Loading my_data.csv...\n",
      "Error reading my_data.csv: [Errno 2] No such file or directory: 'my_data.csv'\n",
      "Cleaning Quant Data Set...\n",
      "Error cleaning my_data.csv: 'NoneType' object has no attribute 'dtype'\n",
      "Exploring Quant Data Set...\n",
      "\n",
      "\n",
      "---Creating QualDataSet---\n",
      "Error reading my_data.csv: [Errno 2] No such file or directory: 'my_data.csv'\n",
      "Loading my_data.csv...\n",
      "Error reading my_data.csv: [Errno 2] No such file or directory: 'my_data.csv'\n",
      "Cleaning Qual Data Set...\n",
      "Exploring Qual Data Set...\n",
      "\n",
      "\n",
      "---Creating simple KNN classifiers---\n",
      "Training...\n",
      "Testing...\n",
      "\n",
      "\n",
      "---Creating kdTree KNN classifiers--- \n",
      "Training...\n",
      "Testing...\n",
      "\n",
      "\n",
      "---Creating experiment--- \n",
      "Running 5-fold cross validation...\n",
      "Scoring...\n",
      "Creating confusion matrix...\n"
     ]
    }
   ],
   "source": [
    "#* project_deliverable_2.ipynb\n",
    "#*\n",
    "#* ANLY 555 2023\n",
    "#* Project <>\n",
    "#*\n",
    "#* Due on: 10/04/2023\n",
    "#* Author(s): Landon Carpenter\n",
    "#*\n",
    "#*\n",
    "#* In accordance with the class policies and Georgetown's\n",
    "#* Honor Code, I certify that, with the exception of the\n",
    "#* class resources and those items noted below, I have neither\n",
    "#* given nor received any assistance on this project other than\n",
    "#* the TAs, professor, textbook and teammates.\n",
    "#*\n",
    "\n",
    "import csv\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import wordcloud\n",
    "\n",
    "#create dataset class\n",
    "class DataSet:\n",
    "    \"\"\"\n",
    "    Class for managing the dataset\n",
    "    \n",
    "    Attribute:\n",
    "        filename (str): the name of the file to be read in\n",
    "    \"\"\"\n",
    "\n",
    "    #constructor\n",
    "    def __init__(self, filename, ):\n",
    "        \"\"\"\n",
    "        Initializes the DataSet class\n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "        self.data = None\n",
    "\n",
    "    #create the framework and stubs for __readFromCSV, __load, clean, and explore\n",
    "    def __readFromCSV(self, filename, header = True):\n",
    "        \"\"\"\n",
    "        Reads in the data from a CSV file. The data is stored on a column basis similar to a parquet file to more easily account for data types.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(filename, 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                data = list(reader)\n",
    "\n",
    "                if header:\n",
    "                    header = data[0]\n",
    "                    data = data[1:]\n",
    "                else:\n",
    "                    header = [f\"col_{i}\" for i in range(len(data[0]))]\n",
    "\n",
    "                #init the dict to store the data\n",
    "                columns = {col_name: [] for col_name in header}\n",
    "\n",
    "                for row in data:\n",
    "                    for col_name, value in zip(header, row):\n",
    "                        try:\n",
    "                            columns[col_name].append(float(value))\n",
    "                        except:\n",
    "                            columns[col_name].append(value)\n",
    "                            #if the value is '' then replace it with np.nan\n",
    "                            if value == '':\n",
    "                                columns[col_name][-1] = np.nan\n",
    "                            else:\n",
    "                                pass\n",
    "\n",
    "\n",
    "                #ok now convert to numpy array\n",
    "                d_type = [(col_name, object if any(isinstance(val, str) for val in columns[col_name]) else float) for col_name in header]\n",
    "                self.data = np.array(list(zip(*[columns[col_name] for col_name in header])), dtype = d_type)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {str(e)}\")\n",
    "\n",
    "                    \n",
    "                        \n",
    "\n",
    "\n",
    "\n",
    "    #abstract base class (ABC)\n",
    "    def __load(self, filename):\n",
    "        \"\"\"\n",
    "        Loads the data from a CSV file\n",
    "        \"\"\"\n",
    "        print(f\"Loading {filename}...\")\n",
    "\n",
    "        self.__readFromCSV(filename)\n",
    "\n",
    "    def getType(self):\n",
    "        \"\"\"\n",
    "        This function will be called later in each of the child classes to determine the type of data\n",
    "        \"\"\"\n",
    "\n",
    "        #using while True to avoid infinite loop that I had earlier\n",
    "        while True:\n",
    "            data_type = input(\"Is this data Time Series, Text, Quantitative, or Qualitative? \\nPlease type 'Time', 'Text', 'Quantitative', or 'Qualitative'.\")\n",
    "            #trying to make the prompt a little more forgiving by making the input lowercase and removing whitespace before checking for validity\n",
    "            norm = data_type.lower().strip()\n",
    "\n",
    "            #make sure the type is valid\n",
    "            if norm in ['time', 'text', 'quantitative', 'qualitative']:\n",
    "                return norm\n",
    "\n",
    "            #if the type is not valid they will see this message and be prompted to try again\n",
    "            else:\n",
    "                print(\"Please enter a valid data type.\")\n",
    "\n",
    "\n",
    "    def clean(self):\n",
    "        \"\"\"\n",
    "        Cleans the data\n",
    "        \"\"\"\n",
    "        print(\"Cleaning...\")\n",
    "\n",
    "    def explore(self):\n",
    "        \"\"\"\n",
    "        Explores the data\n",
    "        \"\"\"\n",
    "        print(\"Exploring...\")\n",
    "        \n",
    "\n",
    "#use inheritance to create TimeSeriesDataSet class\n",
    "class TimeSeriesDataSet(DataSet):\n",
    "    \"\"\"\n",
    "    Class for managing the time series dataset\n",
    "    \"\"\"\n",
    "\n",
    "    #constructor\n",
    "    def __init__(self, filename):\n",
    "        \"\"\"\n",
    "        Initializes the TimeSeriesDataSet class\n",
    "        \"\"\"\n",
    "        super().__init__(filename)\n",
    "    #override the clean and explore methods from the DataSet class to be specific to the TimeSeriesDataSet class\n",
    "    def clean(self):\n",
    "        \"\"\"\n",
    "        Cleans the time series data set\n",
    "        \"\"\"\n",
    "        print(\"Cleaning Time Series Data Set...\")\n",
    "    def explore(self):\n",
    "        \"\"\"\n",
    "        Explores the time series data set\n",
    "        \"\"\"\n",
    "        print(\"Exploring Time Series Data Set...\")\n",
    "\n",
    "\n",
    "class TextDataSet(DataSet):\n",
    "    \"\"\"\n",
    "    Class for managing the text dataset. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        \"\"\"\n",
    "        Initializes the TextDataSet class\n",
    "        \"\"\"\n",
    "        super().__init__(filename)\n",
    "\n",
    "    def clean(self):\n",
    "        \"\"\"\n",
    "        Cleans the text data set\n",
    "        \"\"\"\n",
    "        print(\"Cleaning Text Data Set...\")\n",
    "\n",
    "    def explore(self):\n",
    "        \"\"\"\n",
    "        Explores the text data set\n",
    "        \"\"\"\n",
    "        print(\"Exploring Text Data Set...\")\n",
    "\n",
    "\n",
    "#use inheritance to create QuantDataSet class\n",
    "class QuantDataSet(DataSet):\n",
    "    \"\"\"\n",
    "    Class for managing the quantitative dataset\n",
    "    \"\"\"\n",
    "\n",
    "    #constructor\n",
    "    def __init__(self, filename):\n",
    "        \"\"\"\n",
    "        Initializes the QuantDataSet class\n",
    "        \"\"\"\n",
    "        super().__init__(filename)\n",
    "        self.filename = filename\n",
    "        self.data = None\n",
    "\n",
    "    #override the clean and explore methods from the DataSet class to be specific to the QuantDataSet class\n",
    "    def clean(self, header = True):\n",
    "        \"\"\"\n",
    "        Cleans the quantitative data set\n",
    "        \"\"\"\n",
    "        try: \n",
    "            if self.data is None:\n",
    "                self._DataSet__load(self.filename)\n",
    "\n",
    "            print(\"Cleaning Quant Data Set...\")\n",
    "\n",
    "            #iterate by column replacing missing values with the mean\n",
    "            for col_name in self.data.dtype.names:\n",
    "                col_data = self.data[col_name]\n",
    "\n",
    "                #if the data is numeric\n",
    "                if np.issubdtype(col_data.dtype, np.number):\n",
    "                    #replace missing values with the mean limited to 2 decimal places\n",
    "                    col_data[np.isnan(col_data)] = np.round(np.nanmean(col_data), 2)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning {self.filename}: {str(e)}\")\n",
    "\n",
    "    def explore(self):\n",
    "        \"\"\"\n",
    "        Explores the quantitative data set\n",
    "        \"\"\"\n",
    "        print(\"Exploring Quant Data Set...\")\n",
    "\n",
    "#use inheritance to create QualDataSet class\n",
    "class QualDataSet(DataSet):\n",
    "    \"\"\"\n",
    "    Class for managing the qualitative dataset\n",
    "    \"\"\"\n",
    "\n",
    "    #constructor\n",
    "    def __init__(self, filename):\n",
    "        \"\"\"\n",
    "        Initializes the QualDataSet class\n",
    "        \"\"\"\n",
    "        super().__init__(filename)\n",
    "    #override the clean and explore methods from the DataSet class to be specific to the QualDataSet class\n",
    "    def clean(self):\n",
    "        \"\"\" \n",
    "        Cleans the qualitative data set\n",
    "        \"\"\"\n",
    "        print(\"Cleaning Qual Data Set...\")\n",
    "    def explore(self):\n",
    "        \"\"\"\n",
    "        Explores the qualitative data set\n",
    "        \"\"\"\n",
    "        print(\"Exploring Qual Data Set...\")\n",
    "\n",
    "\n",
    "#create class for the classifier \n",
    "class ClassifierAlgotithm:\n",
    "    \"\"\"\n",
    "    Class for managing the classifier algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the ClassifierAlgotithm class\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the classifier algorithm\n",
    "        \"\"\"\n",
    "        print(\"Training...\")\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Tests the classifier algorithm\n",
    "        \"\"\"\n",
    "        print(\"Testing...\")\n",
    "\n",
    "#create class for simpe KNN that inherets from ClassifierAlgotithm\n",
    "class simpleKNNClassifier(ClassifierAlgotithm):\n",
    "    \"\"\"\n",
    "    Class for managing the simple KNN classifier\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the simpleKNNClassifier class\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "#create class for kdTree KNN that inherets from ClassifierAlgotithm\n",
    "class kdTreeKNNClassifier(ClassifierAlgotithm):\n",
    "    \"\"\"\n",
    "    Class for managing the kdTree KNN classifier\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "#create the Experiment class that will run cross validation, get a score given k and, and create a confusion matrix\n",
    "class Experiment:\n",
    "    \"\"\"\n",
    "    Class for managing the experiment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the Experiment class\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def runCrossVal(self, k):\n",
    "        \"\"\"\n",
    "        Runs k-fold cross validation\n",
    "\n",
    "        Args:\n",
    "            k (int): the number of folds to use\n",
    "        \"\"\"\n",
    "        print(f\"Running {k}-fold cross validation...\")\n",
    "\n",
    "    def score(self):\n",
    "        \"\"\"\n",
    "        Scores the experiment\n",
    "        \"\"\"\n",
    "        print(\"Scoring...\")\n",
    "\n",
    "    def __confusionMatrix(self):\n",
    "        \"\"\"\n",
    "        Creates a confusion matrix\n",
    "        \"\"\"\n",
    "        print(\"Creating confusion matrix...\")\n",
    "\n",
    "#main function: if the py file is ran directly then run the main function and perform the following (rather than importing the file and using a function, for example)\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running main to show framework and stubs...\")\n",
    "    print(\"\\n\")\n",
    "    print(\"---Creating dataset---\")\n",
    "    dataset = DataSet(\"my_data.csv\")\n",
    "    dataset._DataSet__readFromCSV(\"my_data.csv\")\n",
    "    dataset._DataSet__load(\"my_data.csv\")\n",
    "    dataset.clean()\n",
    "    dataset.explore()\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"---Creating TimeSeriesDataSet--- \")\n",
    "    ts_dataset = TimeSeriesDataSet(\"my_data.csv\")\n",
    "    ts_dataset._DataSet__readFromCSV(\"my_data.csv\")\n",
    "    ts_dataset._DataSet__load(\"my_data.csv\")\n",
    "    ts_dataset.clean()\n",
    "    ts_dataset.explore()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"---Creating QuantDataSet---\")\n",
    "    quant_dataset = QuantDataSet(\"my_data.csv\")\n",
    "    quant_dataset._DataSet__readFromCSV(\"my_data.csv\")\n",
    "    quant_dataset._DataSet__load(\"my_data.csv\")\n",
    "    quant_dataset.clean()\n",
    "    quant_dataset.explore()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"---Creating QualDataSet---\")\n",
    "    qual_dataset = QualDataSet(\"my_data.csv\")\n",
    "    qual_dataset._DataSet__readFromCSV(\"my_data.csv\")\n",
    "    qual_dataset._DataSet__load(\"my_data.csv\")\n",
    "    qual_dataset.clean()\n",
    "    qual_dataset.explore()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"---Creating simple KNN classifiers---\")\n",
    "    simple_knn = simpleKNNClassifier()\n",
    "    simple_knn.train()\n",
    "    simple_knn.test()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"---Creating kdTree KNN classifiers--- \")\n",
    "    kd_tree_knn = kdTreeKNNClassifier()\n",
    "    kd_tree_knn.train()\n",
    "    kd_tree_knn.test()\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"---Creating experiment--- \")\n",
    "    experiment = Experiment()\n",
    "    experiment.runCrossVal(5)\n",
    "    experiment.score()\n",
    "    experiment._Experiment__confusionMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': 'Quant_Test.csv', 'data': None}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in \"test.csv\" as my_test using DataSet and __readFromCSV\n",
    "test_object = DataSet(\"Quant_Test.csv\")\n",
    "vars(test_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quant Test: Quant_Test.csv\n",
      "Quant Test: None\n",
      "Loading Quant_Test.csv...\n",
      "Cleaning Quant Data Set...\n",
      "Quant Test: Quant_Test.csv\n",
      "Quant Test: [('P1', 11.  , 12., 10.  , 8., 13., 12., 14., 21.,  9.33, 14., 11., 14., 16., 9.,  9., 9., 3., 21., 0.44, 0.5 , 0.39, 0.28, 0.56, 0.5 , 0.61, 1.  , 0.56, 0.61)\n",
      " ('P2',  7.  ,  6., 10.33, 2.,  7.,  1.,  6.,  3.,  3.  ,  3., 11.,  2.,  6., 2.,  0., 6., 0., 10., 0.7 , 0.6 , 0.3 , 0.34, 0.7 , 0.1 , 0.6 , 0.3 , 0.3 , 0.3 )\n",
      " ('P3',  7.  , 11.,  8.  , 9., 10.,  8.,  7., 13., 12.  ,  6., 14.,  9.,  9., 7., 12., 8., 3., 14., 0.36, 0.73, 0.45, 0.55, 0.64, 0.45, 0.36, 0.91, 0.82, 0.48)\n",
      " ('P4',  8.33,  8., 13.  , 5.,  9.,  6.,  9., 13., 13.  , 11.,  8.,  4.,  5., 4., 15., 7., 2., 19., 0.59, 0.35, 0.65, 0.18, 0.41, 0.24, 0.52, 0.65, 0.56, 0.53)]\n",
      "---Vars---\n",
      "{'filename': 'Quant_Test.csv', 'data': array([('P1', 11.  , 12., 10.  , 8., 13., 12., 14., 21.,  9.33, 14., 11., 14., 16., 9.,  9., 9., 3., 21., 0.44, 0.5 , 0.39, 0.28, 0.56, 0.5 , 0.61, 1.  , 0.56, 0.61),\n",
      "       ('P2',  7.  ,  6., 10.33, 2.,  7.,  1.,  6.,  3.,  3.  ,  3., 11.,  2.,  6., 2.,  0., 6., 0., 10., 0.7 , 0.6 , 0.3 , 0.34, 0.7 , 0.1 , 0.6 , 0.3 , 0.3 , 0.3 ),\n",
      "       ('P3',  7.  , 11.,  8.  , 9., 10.,  8.,  7., 13., 12.  ,  6., 14.,  9.,  9., 7., 12., 8., 3., 14., 0.36, 0.73, 0.45, 0.55, 0.64, 0.45, 0.36, 0.91, 0.82, 0.48),\n",
      "       ('P4',  8.33,  8., 13.  , 5.,  9.,  6.,  9., 13., 13.  , 11.,  8.,  4.,  5., 4., 15., 7., 2., 19., 0.59, 0.35, 0.65, 0.18, 0.41, 0.24, 0.52, 0.65, 0.56, 0.53)],\n",
      "      dtype=[('Product_Code', 'O'), ('W0', '<f8'), ('W1', '<f8'), ('W2', '<f8'), ('W3', '<f8'), ('W4', '<f8'), ('W5', '<f8'), ('W6', '<f8'), ('W7', '<f8'), ('W8', '<f8'), ('W9', '<f8'), ('W10', '<f8'), ('W11', '<f8'), ('W12', '<f8'), ('W13', '<f8'), ('W14', '<f8'), ('W15', '<f8'), ('MIN', '<f8'), ('MAX', '<f8'), ('Normalized 0', '<f8'), ('Normalized 1', '<f8'), ('Normalized 2', '<f8'), ('Normalized 3', '<f8'), ('Normalized 4', '<f8'), ('Normalized 5', '<f8'), ('Normalized 6', '<f8'), ('Normalized 7', '<f8'), ('Normalized 8', '<f8'), ('Normalized 9', '<f8')])}\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "quant_test = QuantDataSet(\"Quant_Test.csv\")\n",
    "print(f\"Quant Test: {quant_test.filename}\")\n",
    "print(f\"Quant Test: {quant_test.data}\")\n",
    "quant_test.clean()\n",
    "print(f\"Quant Test: {quant_test.filename}\")\n",
    "print(f\"Quant Test: {quant_test.data}\")\n",
    "print(\"---Vars---\")\n",
    "print(vars(quant_test))\n",
    "print(type(quant_test.data[0][0]))\n",
    "print(type(quant_test.data[1][0]))\n",
    "print(type(quant_test.data[1][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the cleaned data to a new csv file\n",
    "np.savetxt(\"Quant_Test_Cleaned.csv\", quant_test.data, delimiter = \",\", fmt = \"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from Quant_Test.csv...\n"
     ]
    }
   ],
   "source": [
    "test_object._DataSet__readFromCSV(test_object.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.DataSet object at 0x0000029087207A50>\n"
     ]
    }
   ],
   "source": [
    "print(test_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Product_Code', 'W0', 'W1', 'W2', 'W3', 'W4', 'W5', 'W6', 'W7',\n",
       "        'W8', 'W9', 'W10', 'W11', 'W12', 'W13', 'W14', 'W15', 'MIN',\n",
       "        'MAX', 'Normalized 0', 'Normalized 1', 'Normalized 2',\n",
       "        'Normalized 3', 'Normalized 4', 'Normalized 5', 'Normalized 6',\n",
       "        'Normalized 7', 'Normalized 8', 'Normalized 9'],\n",
       "       ['P1', '11', '12', '10', '8', '13', '12', '14', '21', '', '14',\n",
       "        '11', '14', '16', '9', '9', '9', '3', '21', '0.44', '0.5',\n",
       "        '0.39', '0.28', '0.56', '0.5', '0.61', '1', '', '0.61'],\n",
       "       ['P2', '7', '6', '', '2', '7', '1', '6', '3', '3', '3', '', '2',\n",
       "        '6', '2', '0', '6', '0', '10', '0.7', '0.6', '0.3', '', '0.7',\n",
       "        '0.1', '0.6', '0.3', '0.3', '0.3'],\n",
       "       ['P3', '7', '11', '8', '9', '10', '8', '7', '13', '12', '6', '14',\n",
       "        '9', '', '7', '12', '8', '3', '14', '0.36', '0.73', '0.45',\n",
       "        '0.55', '0.64', '0.45', '0.36', '0.91', '0.82', ''],\n",
       "       ['P4', '', '8', '13', '5', '9', '6', '', '13', '13', '11', '8',\n",
       "        '4', '5', '4', '15', '7', '2', '19', '0.59', '0.35', '0.65',\n",
       "        '0.18', '0.41', '0.24', '', '0.65', '', '0.53']], dtype='<U12')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_object.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Product_Code' 'W0' 'W1' 'W2' 'W3' 'W4' 'W5' 'W6' 'W7' 'W8' 'W9' 'W10'\n",
      " 'W11' 'W12' 'W13' 'W14' 'W15' 'MIN' 'MAX' 'Normalized 0' 'Normalized 1'\n",
      " 'Normalized 2' 'Normalized 3' 'Normalized 4' 'Normalized 5'\n",
      " 'Normalized 6' 'Normalized 7' 'Normalized 8' 'Normalized 9']\n"
     ]
    }
   ],
   "source": [
    "print(test_object.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Product_Code' 'W0' 'W1' 'W2' 'W3' 'W4' 'W5' 'W6' 'W7' 'W8' 'W9' 'W10'\n",
      "  'W11' 'W12' 'W13' 'W14' 'W15' 'MIN' 'MAX' 'Normalized 0' 'Normalized 1'\n",
      "  'Normalized 2' 'Normalized 3' 'Normalized 4' 'Normalized 5'\n",
      "  'Normalized 6' 'Normalized 7' 'Normalized 8' 'Normalized 9']\n",
      " ['P1' '11' '12' '10' '8' '13' '12' '14' '21' '' '14' '11' '14' '16' '9'\n",
      "  '9' '9' '3' '21' '0.44' '0.5' '0.39' '0.28' '0.56' '0.5' '0.61' '1' ''\n",
      "  '0.61']\n",
      " ['P2' '7' '6' '' '2' '7' '1' '6' '3' '3' '3' '' '2' '6' '2' '0' '6' '0'\n",
      "  '10' '0.7' '0.6' '0.3' '' '0.7' '0.1' '0.6' '0.3' '0.3' '0.3']\n",
      " ['P3' '7' '11' '8' '9' '10' '8' '7' '13' '12' '6' '14' '9' '' '7' '12'\n",
      "  '8' '3' '14' '0.36' '0.73' '0.45' '0.55' '0.64' '0.45' '0.36' '0.91'\n",
      "  '0.82' '']\n",
      " ['P4' '' '8' '13' '5' '9' '6' '' '13' '13' '11' '8' '4' '5' '4' '15' '7'\n",
      "  '2' '19' '0.59' '0.35' '0.65' '0.18' '0.41' '0.24' '' '0.65' '' '0.53']]\n"
     ]
    }
   ],
   "source": [
    "my_test = test_object.data\n",
    "print(my_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant\n",
      "Please enter a valid data type.\n",
      "q\n",
      "Please enter a valid data type.\n",
      "qualitative\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'qualitative'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_object.getType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
